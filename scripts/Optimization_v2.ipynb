{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy, random, math, itertools\n",
    "from collections import Counter, defaultdict\n",
    "from deap import base, creator, tools, algorithms\n",
    "import os, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = r\"YourProject\\YourProject.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Lane4RoadPoints is a Point Feature class that is created using RoadCenterPoints_NoNearIntersections (this file is created in the preprocessing step). \n",
    "    This file is the filtered version of RoadCenterPoints_NoNearIntersections as it only contains the points of roads with 4 Lanes; as I am assuming that a \n",
    "            bus stop can be alloted in a 4 Lane road only. This filtering process is done in ArcGIS Pro itslef.\n",
    "    \n",
    "    You may change this based on your needs :))\n",
    "'''\n",
    "\n",
    "# INDIVIDUAL GENERATION\n",
    "def generate_individual(n_stops, candidates_fc=\"Lane4RoadPoints\", min_spacing_m=None):\n",
    "    \"\"\"\n",
    "    Returns a Python list of lists:\n",
    "        [[Bus_ID, X_Point, Y_Point], ...]  length = n_stops\n",
    "    \"\"\"\n",
    "    if not arcpy.Exists(candidates_fc):\n",
    "        raise RuntimeError(f\"Candidates not found: {candidates_fc}\")\n",
    "\n",
    "    # Pull candidate XYs\n",
    "    candidates = [(row[0], row[1]) for row in arcpy.da.SearchCursor(candidates_fc, [\"X_POINT\", \"Y_POINT\"])]\n",
    "    if not candidates:\n",
    "        raise RuntimeError(\"No candidate points found in Lane4RoadPoints.\")\n",
    "\n",
    "    # If enforcing spacing, ensure projected units\n",
    "    if min_spacing_m is not None:\n",
    "        sr = arcpy.Describe(candidates_fc).spatialReference\n",
    "        if (sr.linearUnitName or \"\").lower() not in (\"meter\", \"metre\"):\n",
    "            raise ValueError(f\"min_spacing_m requires projected units (meters). Found: {sr.linearUnitName}\")\n",
    "\n",
    "    # Choose K points\n",
    "    if min_spacing_m is None:\n",
    "        if n_stops > len(candidates):\n",
    "            raise ValueError(f\"Requested {n_stops} stops but only {len(candidates)} candidates available.\")\n",
    "        chosen = random.sample(candidates, n_stops)\n",
    "    else:\n",
    "        pool = candidates[:]\n",
    "        random.shuffle(pool)\n",
    "        chosen = []\n",
    "        for x, y in pool:\n",
    "            if len(chosen) >= n_stops:\n",
    "                break\n",
    "            if all(math.hypot(x - cx, y - cy) >= float(min_spacing_m) for cx, cy in chosen):\n",
    "                chosen.append((x, y))\n",
    "        if len(chosen) < n_stops:\n",
    "            raise RuntimeError(\n",
    "                f\"Could only place {len(chosen)} of {n_stops} with spacing {min_spacing_m} m.\"\n",
    "            )\n",
    "\n",
    "    # Build the individual list\n",
    "    individual = []\n",
    "    for i, (x, y) in enumerate(chosen, start=1):\n",
    "        individual.append([i, x, y])\n",
    "\n",
    "    # return individual\n",
    "    return creator.Individual(individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- fuzzy helpers to calculate walking distances  ---\n",
    "'''\n",
    "    \"Given a walking distance, what is the likely walking time?\"\n",
    "    \n",
    "    Instead of using a fixed walking speed, we:\n",
    "        > Accept that walking speed varies\n",
    "        > Accept that people perceive distance non-linearly\n",
    "        > Convert distance → linguistic categories → time → minutes\n",
    "\n",
    "    So both Distance and Time are fuzzy (not exact)\n",
    "\n",
    "    | Distance (m) | Fuzzy meaning |\n",
    "    | ------------ | ------------- |\n",
    "    | 0–150        | VeryNear      |\n",
    "    | ~200         | Near          |\n",
    "    | ~500         | Moderate      |\n",
    "    | ~1000        | Far           |\n",
    "    | >2000        | VeryFar       |\n",
    "\n",
    "    \n",
    "    | Time label | Approx minutes |\n",
    "    | ---------- | -------------- |\n",
    "    | VeryShort  | 0–4            |\n",
    "    | Short      | 3–8            |\n",
    "    | Medium     | 7–14           |\n",
    "    | Long       | 12–22          |\n",
    "    | VeryLong   | 20–40          |\n",
    "\n",
    "\n",
    "    The speed if not hardcoded, but embedded in the shapes:\n",
    "    | Assumption                                  | Effect          |\n",
    "    | ------------------------------------------- | --------------- |\n",
    "    | Short distances → faster perceived speed    | Small times     |\n",
    "    | Long distances → fatigue, crossings, delays | Larger times    |\n",
    "    | Very far → slowing down                     | Upper time tail |\n",
    "\n",
    "    \n",
    "\n",
    "    The reason why this logic was used instead of the typical The Traveling Salesman Problem (TSP) \n",
    "    was because my road centerline file was not fully connected, thus there were issues with finding shortest route ;-;\n",
    "'''\n",
    "\n",
    "def tri(x, a, b, c):\n",
    "    if x <= a or x >= c: return 0.0\n",
    "    if x == b: return 1.0\n",
    "    return (x - a) / (b - a) if x < b else (c - x) / (c - b)\n",
    "\n",
    "def trap(x, a, b, c, d):\n",
    "    if x <= a or x >= d: return 0.0\n",
    "    if b <= x <= c: return 1.0\n",
    "    return (x - a) / (b - a) if a < x < b else (d - x) / (d - c)\n",
    "\n",
    "# Distance membership functions (meters)\n",
    "DIST_MFS = {\n",
    "    \"VeryNear\":  lambda x: trap(x,   0,   0,  80, 150),\n",
    "    \"Near\":      lambda x: tri (x,  80, 200, 350),\n",
    "    \"Moderate\":  lambda x: tri (x, 300, 500, 800),\n",
    "    \"Far\":       lambda x: tri (x, 700,1000,1500),\n",
    "    \"VeryFar\":   lambda x: trap(x,1300,2000,3000,5000),\n",
    "}\n",
    "\n",
    "# Time (minutes) membership functions for 0–40 min\n",
    "TIME_MIN, TIME_MAX, TIME_STEP = 0.0, 40.0, 0.1\n",
    "TIME_POINTS = [TIME_MIN + i*TIME_STEP for i in range(int((TIME_MAX-TIME_MIN)/TIME_STEP)+1)]\n",
    "TIME_MFS = {\n",
    "    \"VeryShort\": lambda t: trap(t, 0, 0, 2, 4),\n",
    "    \"Short\":     lambda t: tri (t, 3, 5, 8),\n",
    "    \"Medium\":    lambda t: tri (t, 7,10,14),\n",
    "    \"Long\":      lambda t: tri (t,12,16,22),\n",
    "    \"VeryLong\":  lambda t: trap(t,20,28,40,40),\n",
    "}\n",
    "RULES = {\n",
    "    \"VeryNear\": \"VeryShort\",\n",
    "    \"Near\":     \"Short\",\n",
    "    \"Moderate\": \"Medium\",\n",
    "    \"Far\":      \"Long\",\n",
    "    \"VeryFar\":  \"VeryLong\",\n",
    "}\n",
    "\n",
    "def estimate_walk_time_minutes(distance_m: float) -> float:\n",
    "    if distance_m is None or (isinstance(distance_m, float) and math.isnan(distance_m)) or distance_m < 0:\n",
    "        return float('nan')\n",
    "    # 1) fuzzify distance\n",
    "    dist_memberships = {k: mf(distance_m) for k, mf in DIST_MFS.items()}\n",
    "    \n",
    "    # 2) rule firing\n",
    "    time_activation = {lbl: 0.0 for lbl in TIME_MFS.keys()}\n",
    "    for d_lbl, mu in dist_memberships.items():\n",
    "        if mu <= 0: continue\n",
    "        t_lbl = RULES[d_lbl]\n",
    "        time_activation[t_lbl] = max(time_activation[t_lbl], mu)\n",
    "        \n",
    "    # 3) aggregate & 4) centroid defuzzification\n",
    "    agg = []\n",
    "    for t in TIME_POINTS:\n",
    "        vals = [min(alpha, TIME_MFS[t_lbl](t)) for t_lbl, alpha in time_activation.items() if alpha > 0]\n",
    "        agg.append(max(vals) if vals else 0.0)\n",
    "    num = sum(t * mu for t, mu in zip(TIME_POINTS, agg))\n",
    "    den = sum(agg)\n",
    "    if den == 0:\n",
    "        return (distance_m / 1.2) / 60.0  # fallback ~1.2 m/s\n",
    "    return num / den\n",
    "\n",
    "# --- updated assign function with fuzzy time included ---\n",
    "def assign_lots_to_nearest_with_attrs(individual, lots_fc=\"Nearest_RoadPoints_From_Lots\", population_field=\"POPULATION\", landuse_field=\"LANDUSE\", decimals=2):\n",
    "    \"\"\"\n",
    "    Returns (same order as 'individual'):\n",
    "      [\n",
    "        [Bus_ID, X_POINT, Y_POINT,\n",
    "         [(LOT_OID, DIST_M, POP_VALUE, LANDUSE, WALK_MIN), ...],\n",
    "         {\"total_population\": float,\n",
    "          \"landuse_counts\": {<landuse>: count, ...},\n",
    "          \"total_walk_min\": float,\n",
    "          \"avg_walk_min\": float}\n",
    "        ], ...\n",
    "      ]\n",
    "    \"\"\"\n",
    "    # Ensure projected units (meters)\n",
    "    sr = arcpy.Describe(lots_fc).spatialReference\n",
    "    if (sr.linearUnitName or \"\").lower() not in (\"meter\", \"metre\"):\n",
    "        raise ValueError(\"Lots must be in a projected CRS (meters) to use Euclidean distances.\")\n",
    "\n",
    "    # Prep result container\n",
    "    busstop_results = {\n",
    "        int(bus_id): [int(bus_id), (float(x)), (float(y)), [],\n",
    "                      {\"total_population\": 0.0, \"landuse_counts\": {}, \"total_walk_min\": 0.0, \"avg_walk_min\": 0.0}]\n",
    "        for bus_id, x, y in individual\n",
    "    }\n",
    "\n",
    "    # Cursor fields\n",
    "    fields = [\"OID@\", \"SHAPE@XY\"]\n",
    "    pop_idx = land_idx = None\n",
    "    if population_field:\n",
    "        fields.append(population_field); pop_idx = len(fields) - 1\n",
    "    if landuse_field:\n",
    "        fields.append(landuse_field);   land_idx = len(fields) - 1\n",
    "\n",
    "    # Assign each lot to its nearest bus stop, compute fuzzy walking time\n",
    "    with arcpy.da.SearchCursor(lots_fc, fields) as cur:\n",
    "        for row in cur:\n",
    "            lot_oid = int(row[0])\n",
    "            lx, ly = row[1]\n",
    "\n",
    "            nearest_bus = None\n",
    "            nearest_dist = float(\"inf\")\n",
    "            for bus_id, bx, by in individual:\n",
    "                d = math.hypot(lx - float(bx), ly - float(by))\n",
    "                if d < nearest_dist:\n",
    "                    nearest_dist = d\n",
    "                    nearest_bus  = int(bus_id)\n",
    "\n",
    "            pop_val  = float(row[pop_idx]) if (pop_idx is not None and row[pop_idx] is not None) else 0.0\n",
    "            land_val = row[land_idx] if (land_idx is not None) else None\n",
    "            walk_min = estimate_walk_time_minutes(nearest_dist)\n",
    "\n",
    "            rec = busstop_results[nearest_bus]\n",
    "            rec[3].append((lot_oid, round(nearest_dist, decimals), round(pop_val, decimals), land_val, round(walk_min, decimals)))\n",
    "\n",
    "    # Aggregate per stop\n",
    "    for bus_id, rec in busstop_results.items():\n",
    "        lots_list = rec[3]\n",
    "        total_pop  = sum(l[2] for l in lots_list)\n",
    "        total_time = sum(l[4] for l in lots_list)\n",
    "        lu_counts  = Counter(l[3] for l in lots_list if l[3] is not None)\n",
    "        n          = len(lots_list)\n",
    "\n",
    "        rec[4][\"total_population\"] = float(round(total_pop, decimals))\n",
    "        rec[4][\"total_walk_min\"]   = float(round(total_time, decimals))\n",
    "        rec[4][\"avg_walk_min\"]     = float(round(total_time / n, decimals)) if n else 0.0\n",
    "        rec[4][\"landuse_counts\"]   = dict(lu_counts)\n",
    "\n",
    "    # Preserve input order\n",
    "    ordered = [busstop_results[int(bus_id)] for bus_id, _, _ in individual]\n",
    "    return ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHILDREN CREATION\n",
    "\n",
    "def mate_individuals(\n",
    "    ind1, ind2,\n",
    "    candidates_fc=\"Lane4RoadPoints\",\n",
    "    decimals=2,\n",
    "    seed=None,\n",
    "    diversity_rate=0.15,      # ~15% of stops re-sampled if child unchanged\n",
    "    min_spacing_m=250,        # spacing target (meters)\n",
    "    max_resample_tries=2000,  # total tries before relaxing / fallback\n",
    "    relax_steps=5,            # how many relax phases\n",
    "    relax_factor=0.85         # each phase: spacing *= relax_factor\n",
    "):\n",
    "    \"\"\"\n",
    "    Half–half crossover with:\n",
    "      - no duplicate XY within a child (after rounding)\n",
    "      - spacing constraint with relaxation backoff\n",
    "      - diversity injection if child == parent\n",
    "      - farthest-point fallback to avoid hard failure\n",
    "    Returns: creator.Individual(child1), creator.Individual(child2)\n",
    "    \"\"\"\n",
    "    if len(ind1) != len(ind2):\n",
    "        raise ValueError(\"Both individuals must have the same number of bus stops\")\n",
    "\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    if not arcpy.Exists(candidates_fc):\n",
    "        raise RuntimeError(f\"Candidates not found: {candidates_fc}\")\n",
    "\n",
    "    # read/clean candidates once (round for stable uniqueness)\n",
    "    raw = [(row[0], row[1]) for row in arcpy.da.SearchCursor(candidates_fc, [\"X_POINT\", \"Y_POINT\"])]\n",
    "    if not raw:\n",
    "        raise RuntimeError(f\"No candidate points in {candidates_fc}\")\n",
    "\n",
    "    candidate_xy = list({(round(float(x), decimals), round(float(y), decimals)) for x, y in raw})\n",
    "\n",
    "    # (optional) spacing needs projected units\n",
    "    if min_spacing_m is not None:\n",
    "        sr = arcpy.Describe(candidates_fc).spatialReference\n",
    "        if (sr.linearUnitName or \"\").lower() not in (\"meter\", \"metre\"):\n",
    "            raise ValueError(\"min_spacing_m requires projected CRS (meters)\")\n",
    "\n",
    "    K = len(ind1)\n",
    "    cut = K // 2\n",
    "\n",
    "    def xy_of(row):\n",
    "        # row is [Bus_ID, X, Y]\n",
    "        return (round(float(row[1]), decimals), round(float(row[2]), decimals))\n",
    "\n",
    "    def ok_spacing_thr(pt, used, thr):\n",
    "        if thr is None or thr <= 0 or not used:\n",
    "            return True\n",
    "        px, py = pt\n",
    "        for (ux, uy) in used:\n",
    "            if math.hypot(px - ux, py - uy) < thr:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def sample_with_relax(used, base_thr):\n",
    "        \"\"\"\n",
    "        Try random samples under a spacing threshold; if no luck, relax multiple times.\n",
    "        If still nothing, pick the farthest unique candidate.\n",
    "        \"\"\"\n",
    "        # 1) try with relax backoff\n",
    "        total_tries = max_resample_tries\n",
    "        tries_per_step = max(1, total_tries // max(1, relax_steps))\n",
    "        thr = float(base_thr) if (base_thr is not None) else 0.0\n",
    "\n",
    "        for step in range(relax_steps):\n",
    "            for _ in range(tries_per_step):\n",
    "                cand = random.choice(candidate_xy)\n",
    "                if cand in used:\n",
    "                    continue\n",
    "                if ok_spacing_thr(cand, used, thr):\n",
    "                    return cand\n",
    "            thr *= float(relax_factor)  # relax spacing\n",
    "\n",
    "        # 2) fallback: farthest unique candidate from used\n",
    "        best = None\n",
    "        best_d = -1.0\n",
    "        for cand in candidate_xy:\n",
    "            if cand in used:\n",
    "                continue\n",
    "            if not used:\n",
    "                return cand  # first placement case\n",
    "            # min distance to used set\n",
    "            dmin = min(math.hypot(cand[0] - ux, cand[1] - uy) for (ux, uy) in used)\n",
    "            if dmin > best_d:\n",
    "                best_d = dmin\n",
    "                best = cand\n",
    "        return best  # may be None if everything was used\n",
    "\n",
    "    def build_child(srcA, srcB):\n",
    "        child = []\n",
    "        used = set()\n",
    "        for i in range(K):\n",
    "            bus_id = i + 1\n",
    "            pref = xy_of(srcA[i] if i < cut else srcB[i])\n",
    "            alt  = xy_of(srcB[i] if i < cut else srcA[i])\n",
    "\n",
    "            chosen = None\n",
    "            # 1) try preferred\n",
    "            if (pref not in used) and ok_spacing_thr(pref, used, min_spacing_m):\n",
    "                chosen = pref\n",
    "            # 2) try alternate\n",
    "            elif (alt not in used) and ok_spacing_thr(alt, used, min_spacing_m):\n",
    "                chosen = alt\n",
    "            else:\n",
    "                # 3) sample with relaxation & fallback\n",
    "                chosen = sample_with_relax(used, min_spacing_m)\n",
    "                if chosen is None:\n",
    "                    # As a last resort, drop spacing and only enforce uniqueness\n",
    "                    for cand in candidate_xy:\n",
    "                        if cand not in used:\n",
    "                            chosen = cand\n",
    "                            break\n",
    "                if chosen is None:\n",
    "                    raise RuntimeError(\"Could not find a non-duplicate XY for child\")\n",
    "\n",
    "            used.add(chosen)\n",
    "            child.append([bus_id, chosen[0], chosen[1]])\n",
    "        return child\n",
    "\n",
    "    child1 = build_child(ind1, ind2)\n",
    "    child2 = build_child(ind2, ind1)\n",
    "\n",
    "    # --- diversity injection if unchanged ---\n",
    "    def inject_diversity(child, parent_ref):\n",
    "        if child == parent_ref and diversity_rate > 0:\n",
    "            n = max(1, int(round(len(child) * diversity_rate)))\n",
    "            idxs = random.sample(range(len(child)), n)\n",
    "            used = {(row[1], row[2]) for row in child}\n",
    "            for idx in idxs:\n",
    "                fresh = sample_with_relax(used, min_spacing_m)\n",
    "                if fresh is not None:\n",
    "                    child[idx][1], child[idx][2] = fresh\n",
    "                    used.add(fresh)\n",
    "        return child\n",
    "\n",
    "    child1 = inject_diversity(child1, ind1)\n",
    "    child2 = inject_diversity(child2, ind2)\n",
    "\n",
    "    return creator.Individual(child1), creator.Individual(child2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUTATION OF INDIVIDUAL\n",
    "\n",
    "def mutate_individual(individual, candidates_fc=\"Lane4RoadPoints\"):\n",
    "    \"\"\"\n",
    "    Mutates an individual by replacing X,Y of randomly chosen bus stop(s)\n",
    "    with new coordinates from Lane4RoadPoints.\n",
    "\n",
    "    Args:\n",
    "        individual   : [[Bus_ID, X, Y], ...]\n",
    "        candidates_fc: feature class with candidate points (must have X_POINT, Y_POINT fields)\n",
    "    \n",
    "    Returns:\n",
    "        (creator.Individual,) tuple\n",
    "    \"\"\"\n",
    "    if not arcpy.Exists(candidates_fc):\n",
    "        raise RuntimeError(f\"Candidates not found: {candidates_fc}\")\n",
    "\n",
    "    # Get all candidate XYs\n",
    "    candidates = [(row[0], row[1]) \n",
    "                  for row in arcpy.da.SearchCursor(candidates_fc, [\"X_POINT\", \"Y_POINT\"])]\n",
    "    if not candidates:\n",
    "        raise RuntimeError(f\"No candidate points found in {candidates_fc}\")\n",
    "\n",
    "    # Copy so we don’t overwrite the input\n",
    "    new_individual = [row[:] for row in individual]\n",
    "\n",
    "    # Keep a set of already used coordinates for uniqueness check\n",
    "    used_coords = {(float(x), float(y)) for _, x, y in new_individual}\n",
    "\n",
    "    # Decide how many stops to mutate\n",
    "    n_mutations = random.randint(1, len(new_individual))\n",
    "    indices_to_mutate = random.sample(range(len(new_individual)), k=n_mutations)\n",
    "\n",
    "    for idx in indices_to_mutate:\n",
    "        bus_id = new_individual[idx][0]\n",
    "\n",
    "        # Try until we find a candidate not already used\n",
    "        tries = 0\n",
    "        while True:\n",
    "            new_x, new_y = random.choice(candidates)\n",
    "            coord = (float(new_x), float(new_y))\n",
    "            if coord not in used_coords:\n",
    "                used_coords.add(coord)\n",
    "                new_individual[idx] = [bus_id, new_x, new_y]\n",
    "                break\n",
    "            tries += 1\n",
    "            if tries > 100:  # fail-safe to avoid infinite loop\n",
    "                raise RuntimeError(\"Could not find unique candidate point for mutation.\")\n",
    "\n",
    "    return (creator.Individual(new_individual),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDIVIDUAL DECODING\n",
    "\n",
    "def decode(ind):\n",
    "    \"\"\"\n",
    "    Evaluate each bus stop in an individual at the lot level.\n",
    "    Returns:\n",
    "      dict {Bus_ID: {\n",
    "        \"X\": float,\n",
    "        \"Y\": float,\n",
    "        \"lots\": [\n",
    "          {\"LOT_OID\": int, \"DIST_M\": float, \"WALK_MIN\": float,\n",
    "           \"POP\": float, \"LANDUSE\": str}\n",
    "        ]\n",
    "      }}\n",
    "    \"\"\"\n",
    "\n",
    "    result = assign_lots_to_nearest_with_attrs(ind, \"Nearest_RoadPoints_From_Lots\", \"POPULATION\", \"LANDUSE\", 3)\n",
    "\n",
    "    eval_dict = {}\n",
    "    for bus_id, x, y, lots, summary in result:\n",
    "        lot_entries = []\n",
    "        for lot_oid, dist, pop, landuse, walk_min in lots:\n",
    "            lot_entries.append({\n",
    "                \"LOT_OID\": lot_oid,\n",
    "                \"DIST_M\": dist,\n",
    "                \"WALK_MIN\": walk_min,\n",
    "                \"POP\": pop,\n",
    "                \"LANDUSE\": landuse\n",
    "            })\n",
    "\n",
    "        eval_dict[bus_id] = {\n",
    "            \"X\": x,\n",
    "            \"Y\": y,\n",
    "            \"lots\": lot_entries\n",
    "        }\n",
    "\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" HELPER FUNCTIONS TO EVALUATE \"\"\"\n",
    "# Computes how much two bus stop service areas overlap\n",
    "def circle_overlap_pct(d, r=250.0):\n",
    "    if d >= 2*r: return 0.0         # No overlap\n",
    "    if d <= 0:   return 100.0       # Same location\n",
    "\n",
    "    # Partial overlap\n",
    "    part1 = 2 * r*r * math.acos(d / (2*r))\n",
    "    part2 = 0.5 * d * math.sqrt(max(0.0, 4*r*r - d*d))\n",
    "    \n",
    "    return (part1 - part2) / (math.pi * r*r) * 100.0\n",
    "\n",
    "# walking-time scorer (returns score, penalty)\n",
    "def score_walk_minutes(t):\n",
    "    if t is None:\n",
    "        return 0, 0\n",
    "    if t <= 5.0:                # Less than 5 min  (+10)\n",
    "        return 10, 0\n",
    "    elif 5.1 <= t <= 6.9:       # (+5)\n",
    "        return 5, 0\n",
    "    elif 7 <= t <= 15.9:        # (−5)\n",
    "        return -5, 5\n",
    "    elif t >= 16.0:             # (−20)\n",
    "        return -20, 20\n",
    "    else:                        \n",
    "        return 0, 0\n",
    "\n",
    "#Bus Stop duplicate checker\n",
    "def score_no_duplicates(evals, penalty_per_extra=50, bonus_if_none=5):\n",
    "    \"\"\"\n",
    "    Penalize duplicate XY among bus stops.\n",
    "\n",
    "    - Each *extra* occurrence of an XY beyond the first incurs a penalty.\n",
    "      e.g., if one XY appears 3 times → 2 extras → 2 * penalty_per_extra.\n",
    "    - If there are no duplicates at all, give a small bonus.\n",
    "\n",
    "    Returns:\n",
    "        duplication_score (int)   # +bonus_if_none if no duplicates\n",
    "        duplication_penalty (int) # k*penalty_per_extra if duplicates found\n",
    "        dup_detail (dict)         # {(x,y): [bus_id, ...]} for duplicates\n",
    "    \"\"\"\n",
    "    xy_to_ids = defaultdict(list)\n",
    "    for bus_id, data in evals.items():\n",
    "        x = float(data[\"X\"])\n",
    "        y = float(data[\"Y\"])\n",
    "        xy_to_ids[(x, y)].append(int(bus_id))\n",
    "\n",
    "    extras = 0\n",
    "    dup_detail = {}\n",
    "    for xy, ids in xy_to_ids.items():\n",
    "        if len(ids) > 1:\n",
    "            extras += (len(ids) - 1)\n",
    "            dup_detail[xy] = ids[:]  # record duplicates\n",
    "\n",
    "    if extras == 0:\n",
    "        return bonus_if_none, 0, {}\n",
    "    else:\n",
    "        return 0, extras * penalty_per_extra, dup_detail\n",
    "\n",
    "def score_min_residential(evals, min_required=3, bonus_per_stop_meets=2, penalty_per_missing=5):\n",
    "    \"\"\"\n",
    "    Ensure each bus stop serves at least `min_required` Residential lots.\n",
    "    Returns (res_bonus, res_penalty, per_stop_counts)\n",
    "    \"\"\"\n",
    "    res_bonus = 0\n",
    "    res_penalty = 0\n",
    "    per_stop_counts = {}\n",
    "\n",
    "    for bus_id, data in evals.items():\n",
    "        cnt = sum(1 for lot in data[\"lots\"]\n",
    "                  if str(lot.get(\"LANDUSE\", \"\")).strip().lower() == \"residential\")\n",
    "        per_stop_counts[bus_id] = cnt\n",
    "        missing = max(0, min_required - cnt)\n",
    "        if missing == 0:\n",
    "            res_bonus += bonus_per_stop_meets\n",
    "        else:\n",
    "            res_penalty += missing * penalty_per_missing\n",
    "\n",
    "    return res_bonus, res_penalty, per_stop_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prioritize_pareto_front(best_individuals):\n",
    "    \"\"\"\n",
    "    Prioritize individuals\n",
    "    \"\"\"\n",
    "    def get_fitness_values(ind):\n",
    "        total_penalty, bonus, pop_score, walk_score, duplication_score, res_bonus = ind.fitness.values\n",
    "        return (walk_score, duplication_score, bonus, pop_score, -total_penalty)\n",
    "\n",
    "    # Sort individuals based on diversity, compatibility, and violations\n",
    "    prioritized_solutions = sorted(best_individuals, key=get_fitness_values)\n",
    "\n",
    "    return prioritized_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ind, r):\n",
    "    \"\"\"\n",
    "    Multi-objective\n",
    "    \"\"\"\n",
    "    # decode returns: {Bus_ID: {\"X\": float, \"Y\": float, \"lots\": [{\"POP\",\"WALK_MIN\",...}, ...]}}\n",
    "    evals = decode(ind)\n",
    "\n",
    "    # ---------- 1) Overlap (global, all pairs) ----------\n",
    "    stops = [(bus_id, data[\"X\"], data[\"Y\"]) for bus_id, data in evals.items()]\n",
    "    n = len(stops)\n",
    "    n_pairs = n * (n - 1) // 2 if n >= 2 else 0\n",
    "\n",
    "    non_overlap_count = 0\n",
    "    overlap_penalty = 0\n",
    "\n",
    "    for (id1, x1, y1), (id2, x2, y2) in itertools.combinations(stops, 2):\n",
    "        d = math.hypot(x2 - x1, y2 - y1)\n",
    "        p = circle_overlap_pct(d, r=r)\n",
    "\n",
    "        # RULES:\n",
    "        if p <= 30.0:\n",
    "            non_overlap_count += 1\n",
    "        elif 30.0 < p <= 60.0:\n",
    "            overlap_penalty += 10\n",
    "        else:  # p >= 61.0\n",
    "            overlap_penalty += 20\n",
    "\n",
    "    # Normalize bonus so it doesn't explode with many stops (scale to [0..5])\n",
    "    bonus = 100.0 * (non_overlap_count / n_pairs) if n_pairs else 0.0\n",
    "\n",
    "    # ---------- 2) Population per stop ----------\n",
    "    pop_score = 0\n",
    "    pop_penalty = 0\n",
    "    for bus_id, data in evals.items():\n",
    "        pop_total = sum(lot[\"POP\"] for lot in data[\"lots\"])\n",
    "        if pop_total <= 500:\n",
    "            pop_score -= 20\n",
    "            pop_penalty += 20\n",
    "        elif 501 <= pop_total < 2000:\n",
    "            pop_score -= 10\n",
    "            pop_penalty += 10\n",
    "        elif 2000 <= pop_total <= 5000:\n",
    "            pop_score += 5\n",
    "        elif 5001 <= pop_total <= 30000:\n",
    "            pop_score += 15\n",
    "        elif pop_total > 30001:\n",
    "            pop_score += 20\n",
    "\n",
    "    # ---------- 3) Walking time per lot ----------\n",
    "    walk_score = 0\n",
    "    walk_penalty = 0\n",
    "    for bus_id, data in evals.items():\n",
    "        for lot in data[\"lots\"]:\n",
    "            s, pen = score_walk_minutes(lot[\"WALK_MIN\"])\n",
    "            walk_score += s\n",
    "            walk_penalty += pen\n",
    "\n",
    "    # ---------- 4) No duplicated Bus Stops (when mutated and/or crossovered) ----------\n",
    "    duplication_score, duplication_penalty, dup_detail = score_no_duplicates(evals, penalty_per_extra=57, bonus_if_none=5)\n",
    "\n",
    "\n",
    "    # ------- 5) A Bus Stop must have at least 3 'Residential' lots\n",
    "    res_bonus, res_penalty, res_counts = score_min_residential(evals, min_required=3, bonus_per_stop_meets=2, penalty_per_missing=5)\n",
    "\n",
    "    \n",
    "    # ---------- Combine ----------\n",
    "    total_penalty = overlap_penalty + pop_penalty + walk_penalty + duplication_penalty + res_penalty\n",
    "    score = bonus + pop_score + walk_score + duplication_score + res_bonus - total_penalty \n",
    "\n",
    "    # Minimize total_penalty\n",
    "    # Maximize bonus, pop_score, walk_score, duplication_score, res_bonus\n",
    "    return total_penalty, bonus, pop_score, walk_score, duplication_score, res_bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up NSGA-II\n",
    "numStops = 50\n",
    "candidates_fc=\"Lane4RoadPoints\"\n",
    "min_spacing_m = 100\n",
    "\n",
    "# Parameters for NSGA2\n",
    "pop_size = 40\n",
    "generations = 5\n",
    "prob_cx = 0.6\n",
    "prob_mut = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(creator, \"FitnessMulti\"):\n",
    "    delattr(creator, \"FitnessMulti\")\n",
    "creator.create(\"FitnessMulti\", base.Fitness, weights=(-1.0, +1.0, +1.0, +1.0, +1.0, +1.0))\n",
    "\n",
    "if hasattr(creator, \"Individual\"):\n",
    "    delattr(creator, \"Individual\")\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "\n",
    "# Register the evaluation function\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\n",
    "    \"gen_individual\",\n",
    "    generate_individual,\n",
    "    n_stops=numStops,\n",
    "    candidates_fc=candidates_fc,\n",
    "    min_spacing_m=min_spacing_m\n",
    ")\n",
    "\n",
    "# Wrap it into an Individual class\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.gen_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# --- History setup (to see the best solution per generation) ---\n",
    "history = tools.History()\n",
    "toolbox.register(\"clone\", copy.deepcopy)\n",
    "\n",
    "# --- Normal DEAP setup ---\n",
    "toolbox.register(\"evaluate\", evaluate, r=min_spacing_m)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "toolbox.register(\"mutate\", mutate_individual, candidates_fc=candidates_fc)\n",
    "toolbox.register(\"mate\", mate_individuals)\n",
    "\n",
    "\n",
    "# Decorate variation ops for history\n",
    "toolbox.decorate(\"mate\", history.decorator)\n",
    "toolbox.decorate(\"mutate\", history.decorator)\n",
    "\n",
    "# --- Create ONE population and init history on it ---\n",
    "starting_pop = toolbox.population(n=pop_size)\n",
    "history.update(starting_pop)\n",
    "\n",
    "hof = tools.HallOfFame(5)\n",
    "\n",
    "# --- Custom eaMuPlusLambda that updates history each generation ---\n",
    "def eaMuPlusLambda_with_history(population, toolbox, mu, lambda_, cxpb, mutpb, ngen,\n",
    "                               halloffame=None, verbose=True):\n",
    "    \n",
    "    best_by_gen = []      # list of Individuals (one per gen)\n",
    "    \n",
    "    # Evaluate initial population\n",
    "    invalid = [ind for ind in population if not ind.fitness.valid]\n",
    "    fits = map(toolbox.evaluate, invalid)\n",
    "    for ind, fit in zip(invalid, fits):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # NSGA-II needs crowding distances assigned; selNSGA2 does that.\n",
    "    population = toolbox.select(population, len(population))\n",
    "\n",
    "    best0 = prioritize_pareto_front(population)[0]\n",
    "    best_by_gen.append(toolbox.clone(best0))\n",
    "\n",
    "    if halloffame is not None:\n",
    "        halloffame.update(population)\n",
    "\n",
    "    for gen in range(1, ngen + 1):\n",
    "        # Variation (offspring creation)\n",
    "        offspring = algorithms.varOr(population, toolbox, lambda_, cxpb, mutpb)\n",
    "\n",
    "        # update history AFTER variation\n",
    "        history.update(offspring) \n",
    "\n",
    "        # Evaluate offspring\n",
    "        invalid = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fits = map(toolbox.evaluate, invalid)\n",
    "        for ind, fit in zip(invalid, fits):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Select next generation\n",
    "        population = toolbox.select(population + offspring, mu)\n",
    "\n",
    "        # best of this generation\n",
    "        bestg = prioritize_pareto_front(population)[0]\n",
    "        best_by_gen.append(toolbox.clone(bestg))\n",
    "\n",
    "        if halloffame is not None:\n",
    "            halloffame.update(population)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"gen={gen} done\")\n",
    "\n",
    "    return population, best_by_gen\n",
    "\n",
    "final_pop, best_by_gen = eaMuPlusLambda_with_history(\n",
    "    population=starting_pop,    # Parent population\n",
    "    toolbox=toolbox,\n",
    "    mu=pop_size,                # Number of parents\n",
    "    lambda_=(pop_size * 2),     # Number of offspring\n",
    "    cxpb=prob_cx,               # Crossover probability\n",
    "    mutpb=prob_mut,             # Mutation probability\n",
    "    ngen=generations,           # Number of generations\n",
    "    halloffame=hof,             # Hall of Fame for tracking the best individuals\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "prioritized_solutions = prioritize_pareto_front(hof)\n",
    "best_prioritized_individual = prioritized_solutions[0]\n",
    "\n",
    "print(best_prioritized_individual)\n",
    "print(len(best_by_gen), \"generations saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- SAVE AND DISPLAY BEST SOLUTION PER GENERATION ----\n",
    "\n",
    "def write_best_gen_points(individual, out_fc, gen_idx=None, sr_like=\"Lane4RoadPoints\"):\n",
    "    \"\"\"\n",
    "    Writes an individual's bus stops to a POINT feature class.\n",
    "    \"\"\"\n",
    "    sr = arcpy.Describe(sr_like).spatialReference\n",
    "\n",
    "    # Create output feature class\n",
    "    out_ws = os.path.dirname(out_fc)\n",
    "    out_name = os.path.basename(out_fc)\n",
    "\n",
    "    if arcpy.Exists(out_fc):\n",
    "        arcpy.management.Delete(out_fc)\n",
    "\n",
    "    arcpy.management.CreateFeatureclass(out_ws, out_name, \"POINT\", spatial_reference=sr)\n",
    "\n",
    "    arcpy.management.AddField(out_fc, \"GEN\", \"LONG\")\n",
    "    arcpy.management.AddField(out_fc, \"Bus_ID\", \"LONG\")\n",
    "    arcpy.management.AddField(out_fc, \"X_POINT\", \"DOUBLE\")\n",
    "    arcpy.management.AddField(out_fc, \"Y_POINT\", \"DOUBLE\")\n",
    "\n",
    "    with arcpy.da.InsertCursor(out_fc, [\"SHAPE@XY\", \"GEN\", \"Bus_ID\", \"X_POINT\", \"Y_POINT\"]) as ic:\n",
    "        for row in list(individual):\n",
    "            bus_id, x, y = row[0], row[1], row[2]\n",
    "            ic.insertRow([(float(x), float(y)), int(gen_idx or 0), int(bus_id), float(x), float(y)])\n",
    "\n",
    "    return out_fc\n",
    "\n",
    "out_gdb = arcpy.env.workspace\n",
    "name_prefix = \"BestStops_Gen\"\n",
    "\n",
    "out_fcs = []\n",
    "for gen_idx, ind in enumerate(best_by_gen):\n",
    "    out_fc = os.path.join(out_gdb, f\"{name_prefix}_{gen_idx:03d}\")\n",
    "    out_fcs.append(write_best_gen_points(ind, out_fc, gen_idx=gen_idx, sr_like=candidates_fc))\n",
    "    print(\"Wrote:\", out_fc)\n",
    "\n",
    "print(\"Done. Feature classes created:\", len(out_fcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- DISPLAY THE OPTIMAL BUS STOP LOCATIONS ON ARCGIS MAP ----\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "arcpy.env.workspace = r\"YourProject\\YourProject.gdb\"\n",
    "\n",
    "OUT_POINTS = \"GA_Best_Stops\"          # name for the points FC\n",
    "SR_LIKE    = \"Lane4RoadPoints\"        # copy spatial reference from this layer\n",
    "LOTS_FC    = \"Nearest_RoadPoints_From_Lots\"  # optional (for spider lines)\n",
    "OUT_LINES  = \"GA_Best_SpiderLines\"    # optional (for spider lines)\n",
    "\n",
    "ind = list(best_prioritized_individual)\n",
    "\n",
    "# ---- Create points FC from the individual ----\n",
    "sr = arcpy.Describe(SR_LIKE).spatialReference\n",
    "if arcpy.Exists(OUT_POINTS):\n",
    "    arcpy.management.Delete(OUT_POINTS)\n",
    "\n",
    "arcpy.management.CreateFeatureclass(arcpy.env.workspace, OUT_POINTS, \"POINT\", spatial_reference=sr)\n",
    "arcpy.management.AddField(OUT_POINTS, \"Bus_ID\",  \"LONG\")\n",
    "arcpy.management.AddField(OUT_POINTS, \"X_POINT\", \"DOUBLE\")\n",
    "arcpy.management.AddField(OUT_POINTS, \"Y_POINT\", \"DOUBLE\")\n",
    "\n",
    "with arcpy.da.InsertCursor(OUT_POINTS, [\"SHAPE@XY\", \"Bus_ID\", \"X_POINT\", \"Y_POINT\"]) as ic:\n",
    "    for bus_id, x, y in ind:\n",
    "        ic.insertRow([(float(x), float(y)), int(bus_id), float(x), float(y)])\n",
    "\n",
    "# ---- Add the points to the current map (and label by Bus_ID) ----\n",
    "try:\n",
    "    aprx = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "    m = aprx.activeMap\n",
    "    lyr = m.addDataFromPath(arcpy.Describe(OUT_POINTS).catalogPath)\n",
    "\n",
    "    # quick labeling by Bus_ID\n",
    "    lyr.showLabels = True\n",
    "    if hasattr(lyr, \"listLabelClasses\"):\n",
    "        for lc in lyr.listLabelClasses():\n",
    "            lc.expression = \"$feature.Bus_ID\"\n",
    "\n",
    "    # optional: unique values symbology by Bus_ID\n",
    "    try:\n",
    "        sym = lyr.symbology\n",
    "        sym.updateRenderer('UniqueValueRenderer')\n",
    "        sym.renderer.fields = ['Bus_ID']\n",
    "        lyr.symbology = sym\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    aprx.save()\n",
    "except Exception as e:\n",
    "    print(\"Layer add skipped (not in ArcGIS Pro UI?):\", e)\n",
    "\n",
    "print(f\"✓ Wrote {OUT_POINTS} and added to map.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- OPTIONAL: DISPLAY THE LOT TO BUS STOP SPIDERLINE ON ARCGIS MAP ----------------\n",
    "\n",
    "result = assign_lots_to_nearest_with_attrs(\n",
    "    individual=ind,\n",
    "    lots_fc=LOTS_FC,\n",
    "    population_field=\"POPULATION\",\n",
    "    landuse_field=\"LANDUSE\",\n",
    "    decimals=2\n",
    ")\n",
    "\n",
    "# cache lot geometries\n",
    "lot_geom = {oid: shp for oid, shp in arcpy.da.SearchCursor(LOTS_FC, [\"OID@\", \"SHAPE@\"])}\n",
    "\n",
    "if arcpy.Exists(OUT_LINES):\n",
    "    arcpy.management.Delete(OUT_LINES)\n",
    "    \n",
    "arcpy.management.CreateFeatureclass(arcpy.env.workspace, OUT_LINES, \"POLYLINE\", spatial_reference=sr)\n",
    "for nm, tp in [(\"Bus_ID\",\"LONG\"), (\"LOT_OID\",\"LONG\"), (\"DIST_M\",\"DOUBLE\"), (\"POP\",\"DOUBLE\"), (\"LANDUSE\",\"TEXT\"), (\"WALK_MIN\",\"DOUBLE\")]:\n",
    "    arcpy.management.AddField(OUT_LINES, nm, tp, field_length=64 if tp==\"TEXT\" else None)\n",
    "\n",
    "with arcpy.da.InsertCursor(OUT_LINES, [\"SHAPE@\", \"Bus_ID\", \"LOT_OID\", \"DIST_M\", \"POP\", \"LANDUSE\", \"WALK_MIN\"]) as ic:\n",
    "    for bus_id, sx, sy, lot_list, _summary in result:\n",
    "        stop_pt = arcpy.PointGeometry(arcpy.Point(float(sx), float(sy)), sr)\n",
    "        for lot_oid, dist_m, pop, landuse, walk_min in lot_list:\n",
    "            lp = lot_geom.get(int(lot_oid))\n",
    "            if lp:\n",
    "                line = arcpy.Polyline(arcpy.Array([stop_pt.firstPoint, lp.firstPoint]), sr)\n",
    "                ic.insertRow([line, int(bus_id), int(lot_oid), float(dist_m), float(pop), landuse, float(walk_min)])\n",
    "\n",
    "# Add to map\n",
    "try:\n",
    "   \n",
    "    # Remove existing spiderline layers with the same name (and \"(2)\" variants)\n",
    "    for lyr in m.listLayers():\n",
    "        if lyr.name == OUT_LINES or lyr.name.startswith(f\"{OUT_LINES} (\"):\n",
    "            m.removeLayer(lyr)\n",
    "    \n",
    "    lyr_lines = m.addDataFromPath(arcpy.Describe(OUT_LINES).catalogPath)\n",
    "    aprx.save()\n",
    "except Exception as e:\n",
    "    print(\"Could not add lines to map:\", e)\n",
    "print(f\"✓ Wrote {OUT_LINES} and added to map.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
